{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "df = pd.read_csv('vehicles.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Видалення аутлайнерів по цінам"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8177 ( 1.92 % ) outliers removed from dataset\n"
     ]
    }
   ],
   "source": [
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "filter = (df['price'] >= Q1 - 1.5 * IQR) & (df['price'] <= Q3 + 1.5 * IQR)\n",
    "init_size = df.count()['id']\n",
    "df = df.loc[filter]\n",
    "filtered_size = df.count()['id']\n",
    "print(init_size - filtered_size, '(', '{:.2f}'.format(100 * (init_size - filtered_size) / init_size), '%', ')',\n",
    "      'outliers removed from dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Філтрація по року і ціні"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "                id                                                url  \\\n27      7316814884  https://auburn.craigslist.org/ctd/d/auburn-uni...   \n28      7316814758  https://auburn.craigslist.org/ctd/d/auburn-uni...   \n29      7316814989  https://auburn.craigslist.org/ctd/d/auburn-uni...   \n30      7316743432  https://auburn.craigslist.org/ctd/d/auburn-uni...   \n31      7316356412  https://auburn.craigslist.org/cto/d/auburn-uni...   \n...            ...                                                ...   \n426875  7301591192  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n426876  7301591187  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n426877  7301591147  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n426878  7301591140  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n426879  7301591129  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n\n         region                      region_url  price    year manufacturer  \\\n27       auburn   https://auburn.craigslist.org  33590  2014.0          gmc   \n28       auburn   https://auburn.craigslist.org  22590  2010.0    chevrolet   \n29       auburn   https://auburn.craigslist.org  39590  2020.0    chevrolet   \n30       auburn   https://auburn.craigslist.org  30990  2017.0       toyota   \n31       auburn   https://auburn.craigslist.org  15000  2013.0         ford   \n...         ...                             ...    ...     ...          ...   \n426875  wyoming  https://wyoming.craigslist.org  23590  2019.0       nissan   \n426876  wyoming  https://wyoming.craigslist.org  30590  2020.0        volvo   \n426877  wyoming  https://wyoming.craigslist.org  34990  2020.0     cadillac   \n426878  wyoming  https://wyoming.craigslist.org  28990  2018.0        lexus   \n426879  wyoming  https://wyoming.craigslist.org  30590  2019.0          bmw   \n\n                           model  condition    cylinders  ...       size  \\\n27      sierra 1500 crew cab slt       good  8 cylinders  ...        NaN   \n28                silverado 1500       good  8 cylinders  ...        NaN   \n29           silverado 1500 crew       good  8 cylinders  ...        NaN   \n30          tundra double cab sr       good  8 cylinders  ...        NaN   \n31                     f-150 xlt  excellent  6 cylinders  ...  full-size   \n...                          ...        ...          ...  ...        ...   \n426875         maxima s sedan 4d       good  6 cylinders  ...        NaN   \n426876  s60 t5 momentum sedan 4d       good          NaN  ...        NaN   \n426877          xt4 sport suv 4d       good          NaN  ...        NaN   \n426878           es 350 sedan 4d       good  6 cylinders  ...        NaN   \n426879  4 series 430i gran coupe       good          NaN  ...        NaN   \n\n             type paint_color  \\\n27         pickup       white   \n28         pickup        blue   \n29         pickup         red   \n30         pickup         red   \n31          truck       black   \n...           ...         ...   \n426875      sedan         NaN   \n426876      sedan         red   \n426877  hatchback       white   \n426878      sedan      silver   \n426879      coupe         NaN   \n\n                                                image_url  \\\n27      https://images.craigslist.org/00R0R_lwWjXSEWNa...   \n28      https://images.craigslist.org/00R0R_lwWjXSEWNa...   \n29      https://images.craigslist.org/01212_jjirIWa0y0...   \n30      https://images.craigslist.org/00x0x_1y9kIOzGCF...   \n31      https://images.craigslist.org/00404_l4loxHvdQe...   \n...                                                   ...   \n426875  https://images.craigslist.org/00o0o_iiraFnHg8q...   \n426876  https://images.craigslist.org/00x0x_15sbgnxCIS...   \n426877  https://images.craigslist.org/00L0L_farM7bxnxR...   \n426878  https://images.craigslist.org/00z0z_bKnIVGLkDT...   \n426879  https://images.craigslist.org/00Y0Y_lEUocjyRxa...   \n\n                                              description county state  \\\n27      Carvana is the safer way to buy a car During t...    NaN    al   \n28      Carvana is the safer way to buy a car During t...    NaN    al   \n29      Carvana is the safer way to buy a car During t...    NaN    al   \n30      Carvana is the safer way to buy a car During t...    NaN    al   \n31      2013 F-150 XLT V6 4 Door. Good condition. Leve...    NaN    al   \n...                                                   ...    ...   ...   \n426875  Carvana is the safer way to buy a car During t...    NaN    wy   \n426876  Carvana is the safer way to buy a car During t...    NaN    wy   \n426877  Carvana is the safer way to buy a car During t...    NaN    wy   \n426878  Carvana is the safer way to buy a car During t...    NaN    wy   \n426879  Carvana is the safer way to buy a car During t...    NaN    wy   \n\n              lat       long              posting_date  \n27      32.590000 -85.480000  2021-05-04T12:31:18-0500  \n28      32.590000 -85.480000  2021-05-04T12:31:08-0500  \n29      32.590000 -85.480000  2021-05-04T12:31:25-0500  \n30      32.590000 -85.480000  2021-05-04T10:41:31-0500  \n31      32.592000 -85.518900  2021-05-03T14:02:03-0500  \n...           ...        ...                       ...  \n426875  33.786500 -84.445400  2021-04-04T03:21:31-0600  \n426876  33.786500 -84.445400  2021-04-04T03:21:29-0600  \n426877  33.779214 -84.411811  2021-04-04T03:21:17-0600  \n426878  33.786500 -84.445400  2021-04-04T03:21:11-0600  \n426879  33.779214 -84.411811  2021-04-04T03:21:07-0600  \n\n[369037 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url</th>\n      <th>region</th>\n      <th>region_url</th>\n      <th>price</th>\n      <th>year</th>\n      <th>manufacturer</th>\n      <th>model</th>\n      <th>condition</th>\n      <th>cylinders</th>\n      <th>...</th>\n      <th>size</th>\n      <th>type</th>\n      <th>paint_color</th>\n      <th>image_url</th>\n      <th>description</th>\n      <th>county</th>\n      <th>state</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>posting_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27</th>\n      <td>7316814884</td>\n      <td>https://auburn.craigslist.org/ctd/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>33590</td>\n      <td>2014.0</td>\n      <td>gmc</td>\n      <td>sierra 1500 crew cab slt</td>\n      <td>good</td>\n      <td>8 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>pickup</td>\n      <td>white</td>\n      <td>https://images.craigslist.org/00R0R_lwWjXSEWNa...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.590000</td>\n      <td>-85.480000</td>\n      <td>2021-05-04T12:31:18-0500</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>7316814758</td>\n      <td>https://auburn.craigslist.org/ctd/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>22590</td>\n      <td>2010.0</td>\n      <td>chevrolet</td>\n      <td>silverado 1500</td>\n      <td>good</td>\n      <td>8 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>pickup</td>\n      <td>blue</td>\n      <td>https://images.craigslist.org/00R0R_lwWjXSEWNa...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.590000</td>\n      <td>-85.480000</td>\n      <td>2021-05-04T12:31:08-0500</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>7316814989</td>\n      <td>https://auburn.craigslist.org/ctd/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>39590</td>\n      <td>2020.0</td>\n      <td>chevrolet</td>\n      <td>silverado 1500 crew</td>\n      <td>good</td>\n      <td>8 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>pickup</td>\n      <td>red</td>\n      <td>https://images.craigslist.org/01212_jjirIWa0y0...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.590000</td>\n      <td>-85.480000</td>\n      <td>2021-05-04T12:31:25-0500</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>7316743432</td>\n      <td>https://auburn.craigslist.org/ctd/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>30990</td>\n      <td>2017.0</td>\n      <td>toyota</td>\n      <td>tundra double cab sr</td>\n      <td>good</td>\n      <td>8 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>pickup</td>\n      <td>red</td>\n      <td>https://images.craigslist.org/00x0x_1y9kIOzGCF...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.590000</td>\n      <td>-85.480000</td>\n      <td>2021-05-04T10:41:31-0500</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>7316356412</td>\n      <td>https://auburn.craigslist.org/cto/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>15000</td>\n      <td>2013.0</td>\n      <td>ford</td>\n      <td>f-150 xlt</td>\n      <td>excellent</td>\n      <td>6 cylinders</td>\n      <td>...</td>\n      <td>full-size</td>\n      <td>truck</td>\n      <td>black</td>\n      <td>https://images.craigslist.org/00404_l4loxHvdQe...</td>\n      <td>2013 F-150 XLT V6 4 Door. Good condition. Leve...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.592000</td>\n      <td>-85.518900</td>\n      <td>2021-05-03T14:02:03-0500</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>426875</th>\n      <td>7301591192</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>23590</td>\n      <td>2019.0</td>\n      <td>nissan</td>\n      <td>maxima s sedan 4d</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>sedan</td>\n      <td>NaN</td>\n      <td>https://images.craigslist.org/00o0o_iiraFnHg8q...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.786500</td>\n      <td>-84.445400</td>\n      <td>2021-04-04T03:21:31-0600</td>\n    </tr>\n    <tr>\n      <th>426876</th>\n      <td>7301591187</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>30590</td>\n      <td>2020.0</td>\n      <td>volvo</td>\n      <td>s60 t5 momentum sedan 4d</td>\n      <td>good</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>sedan</td>\n      <td>red</td>\n      <td>https://images.craigslist.org/00x0x_15sbgnxCIS...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.786500</td>\n      <td>-84.445400</td>\n      <td>2021-04-04T03:21:29-0600</td>\n    </tr>\n    <tr>\n      <th>426877</th>\n      <td>7301591147</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>34990</td>\n      <td>2020.0</td>\n      <td>cadillac</td>\n      <td>xt4 sport suv 4d</td>\n      <td>good</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>hatchback</td>\n      <td>white</td>\n      <td>https://images.craigslist.org/00L0L_farM7bxnxR...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.779214</td>\n      <td>-84.411811</td>\n      <td>2021-04-04T03:21:17-0600</td>\n    </tr>\n    <tr>\n      <th>426878</th>\n      <td>7301591140</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>28990</td>\n      <td>2018.0</td>\n      <td>lexus</td>\n      <td>es 350 sedan 4d</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>sedan</td>\n      <td>silver</td>\n      <td>https://images.craigslist.org/00z0z_bKnIVGLkDT...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.786500</td>\n      <td>-84.445400</td>\n      <td>2021-04-04T03:21:11-0600</td>\n    </tr>\n    <tr>\n      <th>426879</th>\n      <td>7301591129</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>30590</td>\n      <td>2019.0</td>\n      <td>bmw</td>\n      <td>4 series 430i gran coupe</td>\n      <td>good</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>coupe</td>\n      <td>NaN</td>\n      <td>https://images.craigslist.org/00Y0Y_lEUocjyRxa...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.779214</td>\n      <td>-84.411811</td>\n      <td>2021-04-04T03:21:07-0600</td>\n    </tr>\n  </tbody>\n</table>\n<p>369037 rows × 26 columns</p>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['price'] > 600]\n",
    "df = df[df['year'] >= 1970]  # позбуваємось екзотичних авто, які можуть сильно вплинути на тренування моделей\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "                id                                                url  \\\n27      7316814884  https://auburn.craigslist.org/ctd/d/auburn-uni...   \n28      7316814758  https://auburn.craigslist.org/ctd/d/auburn-uni...   \n29      7316814989  https://auburn.craigslist.org/ctd/d/auburn-uni...   \n30      7316743432  https://auburn.craigslist.org/ctd/d/auburn-uni...   \n31      7316356412  https://auburn.craigslist.org/cto/d/auburn-uni...   \n...            ...                                                ...   \n426875  7301591192  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n426876  7301591187  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n426877  7301591147  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n426878  7301591140  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n426879  7301591129  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n\n         region                      region_url  price    year manufacturer  \\\n27       auburn   https://auburn.craigslist.org  33590  2014.0          gmc   \n28       auburn   https://auburn.craigslist.org  22590  2010.0    chevrolet   \n29       auburn   https://auburn.craigslist.org  39590  2020.0    chevrolet   \n30       auburn   https://auburn.craigslist.org  30990  2017.0       toyota   \n31       auburn   https://auburn.craigslist.org  15000  2013.0         ford   \n...         ...                             ...    ...     ...          ...   \n426875  wyoming  https://wyoming.craigslist.org  23590  2019.0       nissan   \n426876  wyoming  https://wyoming.craigslist.org  30590  2020.0        volvo   \n426877  wyoming  https://wyoming.craigslist.org  34990  2020.0     cadillac   \n426878  wyoming  https://wyoming.craigslist.org  28990  2018.0        lexus   \n426879  wyoming  https://wyoming.craigslist.org  30590  2019.0          bmw   \n\n                           model  condition    cylinders  ...       size  \\\n27      sierra 1500 crew cab slt       good  8 cylinders  ...        NaN   \n28                silverado 1500       good  8 cylinders  ...        NaN   \n29           silverado 1500 crew       good  8 cylinders  ...        NaN   \n30          tundra double cab sr       good  8 cylinders  ...        NaN   \n31                     f-150 xlt  excellent  6 cylinders  ...  full-size   \n...                          ...        ...          ...  ...        ...   \n426875         maxima s sedan 4d       good  6 cylinders  ...        NaN   \n426876  s60 t5 momentum sedan 4d       good          NaN  ...        NaN   \n426877          xt4 sport suv 4d       good          NaN  ...        NaN   \n426878           es 350 sedan 4d       good  6 cylinders  ...        NaN   \n426879  4 series 430i gran coupe       good          NaN  ...        NaN   \n\n             type paint_color  \\\n27         pickup       white   \n28         pickup        blue   \n29         pickup         red   \n30         pickup         red   \n31          truck       black   \n...           ...         ...   \n426875      sedan         NaN   \n426876      sedan         red   \n426877  hatchback       white   \n426878      sedan      silver   \n426879      coupe         NaN   \n\n                                                image_url  \\\n27      https://images.craigslist.org/00R0R_lwWjXSEWNa...   \n28      https://images.craigslist.org/00R0R_lwWjXSEWNa...   \n29      https://images.craigslist.org/01212_jjirIWa0y0...   \n30      https://images.craigslist.org/00x0x_1y9kIOzGCF...   \n31      https://images.craigslist.org/00404_l4loxHvdQe...   \n...                                                   ...   \n426875  https://images.craigslist.org/00o0o_iiraFnHg8q...   \n426876  https://images.craigslist.org/00x0x_15sbgnxCIS...   \n426877  https://images.craigslist.org/00L0L_farM7bxnxR...   \n426878  https://images.craigslist.org/00z0z_bKnIVGLkDT...   \n426879  https://images.craigslist.org/00Y0Y_lEUocjyRxa...   \n\n                                              description county state  \\\n27      Carvana is the safer way to buy a car During t...    NaN    al   \n28      Carvana is the safer way to buy a car During t...    NaN    al   \n29      Carvana is the safer way to buy a car During t...    NaN    al   \n30      Carvana is the safer way to buy a car During t...    NaN    al   \n31      2013 F-150 XLT V6 4 Door. Good condition. Leve...    NaN    al   \n...                                                   ...    ...   ...   \n426875  Carvana is the safer way to buy a car During t...    NaN    wy   \n426876  Carvana is the safer way to buy a car During t...    NaN    wy   \n426877  Carvana is the safer way to buy a car During t...    NaN    wy   \n426878  Carvana is the safer way to buy a car During t...    NaN    wy   \n426879  Carvana is the safer way to buy a car During t...    NaN    wy   \n\n              lat       long              posting_date  \n27      32.590000 -85.480000  2021-05-04T12:31:18-0500  \n28      32.590000 -85.480000  2021-05-04T12:31:08-0500  \n29      32.590000 -85.480000  2021-05-04T12:31:25-0500  \n30      32.590000 -85.480000  2021-05-04T10:41:31-0500  \n31      32.592000 -85.518900  2021-05-03T14:02:03-0500  \n...           ...        ...                       ...  \n426875  33.786500 -84.445400  2021-04-04T03:21:31-0600  \n426876  33.786500 -84.445400  2021-04-04T03:21:29-0600  \n426877  33.779214 -84.411811  2021-04-04T03:21:17-0600  \n426878  33.786500 -84.445400  2021-04-04T03:21:11-0600  \n426879  33.779214 -84.411811  2021-04-04T03:21:07-0600  \n\n[365289 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url</th>\n      <th>region</th>\n      <th>region_url</th>\n      <th>price</th>\n      <th>year</th>\n      <th>manufacturer</th>\n      <th>model</th>\n      <th>condition</th>\n      <th>cylinders</th>\n      <th>...</th>\n      <th>size</th>\n      <th>type</th>\n      <th>paint_color</th>\n      <th>image_url</th>\n      <th>description</th>\n      <th>county</th>\n      <th>state</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>posting_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27</th>\n      <td>7316814884</td>\n      <td>https://auburn.craigslist.org/ctd/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>33590</td>\n      <td>2014.0</td>\n      <td>gmc</td>\n      <td>sierra 1500 crew cab slt</td>\n      <td>good</td>\n      <td>8 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>pickup</td>\n      <td>white</td>\n      <td>https://images.craigslist.org/00R0R_lwWjXSEWNa...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.590000</td>\n      <td>-85.480000</td>\n      <td>2021-05-04T12:31:18-0500</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>7316814758</td>\n      <td>https://auburn.craigslist.org/ctd/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>22590</td>\n      <td>2010.0</td>\n      <td>chevrolet</td>\n      <td>silverado 1500</td>\n      <td>good</td>\n      <td>8 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>pickup</td>\n      <td>blue</td>\n      <td>https://images.craigslist.org/00R0R_lwWjXSEWNa...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.590000</td>\n      <td>-85.480000</td>\n      <td>2021-05-04T12:31:08-0500</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>7316814989</td>\n      <td>https://auburn.craigslist.org/ctd/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>39590</td>\n      <td>2020.0</td>\n      <td>chevrolet</td>\n      <td>silverado 1500 crew</td>\n      <td>good</td>\n      <td>8 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>pickup</td>\n      <td>red</td>\n      <td>https://images.craigslist.org/01212_jjirIWa0y0...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.590000</td>\n      <td>-85.480000</td>\n      <td>2021-05-04T12:31:25-0500</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>7316743432</td>\n      <td>https://auburn.craigslist.org/ctd/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>30990</td>\n      <td>2017.0</td>\n      <td>toyota</td>\n      <td>tundra double cab sr</td>\n      <td>good</td>\n      <td>8 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>pickup</td>\n      <td>red</td>\n      <td>https://images.craigslist.org/00x0x_1y9kIOzGCF...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.590000</td>\n      <td>-85.480000</td>\n      <td>2021-05-04T10:41:31-0500</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>7316356412</td>\n      <td>https://auburn.craigslist.org/cto/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>15000</td>\n      <td>2013.0</td>\n      <td>ford</td>\n      <td>f-150 xlt</td>\n      <td>excellent</td>\n      <td>6 cylinders</td>\n      <td>...</td>\n      <td>full-size</td>\n      <td>truck</td>\n      <td>black</td>\n      <td>https://images.craigslist.org/00404_l4loxHvdQe...</td>\n      <td>2013 F-150 XLT V6 4 Door. Good condition. Leve...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.592000</td>\n      <td>-85.518900</td>\n      <td>2021-05-03T14:02:03-0500</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>426875</th>\n      <td>7301591192</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>23590</td>\n      <td>2019.0</td>\n      <td>nissan</td>\n      <td>maxima s sedan 4d</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>sedan</td>\n      <td>NaN</td>\n      <td>https://images.craigslist.org/00o0o_iiraFnHg8q...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.786500</td>\n      <td>-84.445400</td>\n      <td>2021-04-04T03:21:31-0600</td>\n    </tr>\n    <tr>\n      <th>426876</th>\n      <td>7301591187</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>30590</td>\n      <td>2020.0</td>\n      <td>volvo</td>\n      <td>s60 t5 momentum sedan 4d</td>\n      <td>good</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>sedan</td>\n      <td>red</td>\n      <td>https://images.craigslist.org/00x0x_15sbgnxCIS...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.786500</td>\n      <td>-84.445400</td>\n      <td>2021-04-04T03:21:29-0600</td>\n    </tr>\n    <tr>\n      <th>426877</th>\n      <td>7301591147</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>34990</td>\n      <td>2020.0</td>\n      <td>cadillac</td>\n      <td>xt4 sport suv 4d</td>\n      <td>good</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>hatchback</td>\n      <td>white</td>\n      <td>https://images.craigslist.org/00L0L_farM7bxnxR...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.779214</td>\n      <td>-84.411811</td>\n      <td>2021-04-04T03:21:17-0600</td>\n    </tr>\n    <tr>\n      <th>426878</th>\n      <td>7301591140</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>28990</td>\n      <td>2018.0</td>\n      <td>lexus</td>\n      <td>es 350 sedan 4d</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>sedan</td>\n      <td>silver</td>\n      <td>https://images.craigslist.org/00z0z_bKnIVGLkDT...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.786500</td>\n      <td>-84.445400</td>\n      <td>2021-04-04T03:21:11-0600</td>\n    </tr>\n    <tr>\n      <th>426879</th>\n      <td>7301591129</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>30590</td>\n      <td>2019.0</td>\n      <td>bmw</td>\n      <td>4 series 430i gran coupe</td>\n      <td>good</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>coupe</td>\n      <td>NaN</td>\n      <td>https://images.craigslist.org/00Y0Y_lEUocjyRxa...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.779214</td>\n      <td>-84.411811</td>\n      <td>2021-04-04T03:21:07-0600</td>\n    </tr>\n  </tbody>\n</table>\n<p>365289 rows × 26 columns</p>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['price'] + df['odometer']) > 5000]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Видаляєм null значення з вагомих калонок"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "                id                                                url  \\\n31      7316356412  https://auburn.craigslist.org/cto/d/auburn-uni...   \n32      7316343444  https://auburn.craigslist.org/ctd/d/auburn-uni...   \n33      7316304717  https://auburn.craigslist.org/ctd/d/auburn-uni...   \n34      7316285779  https://auburn.craigslist.org/cto/d/auburn-201...   \n35      7316257769  https://auburn.craigslist.org/ctd/d/auburn-uni...   \n...            ...                                                ...   \n426872  7301591201  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n426873  7301591202  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n426874  7301591199  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n426876  7301591187  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n426878  7301591140  https://wyoming.craigslist.org/ctd/d/atlanta-2...   \n\n         region                      region_url  price    year   manufacturer  \\\n31       auburn   https://auburn.craigslist.org  15000  2013.0           ford   \n32       auburn   https://auburn.craigslist.org  27990  2012.0            gmc   \n33       auburn   https://auburn.craigslist.org  34590  2016.0      chevrolet   \n34       auburn   https://auburn.craigslist.org  35000  2019.0         toyota   \n35       auburn   https://auburn.craigslist.org  29990  2016.0      chevrolet   \n...         ...                             ...    ...     ...            ...   \n426872  wyoming  https://wyoming.craigslist.org  32590  2020.0  mercedes-benz   \n426873  wyoming  https://wyoming.craigslist.org  30990  2018.0  mercedes-benz   \n426874  wyoming  https://wyoming.craigslist.org  33590  2018.0          lexus   \n426876  wyoming  https://wyoming.craigslist.org  30590  2020.0          volvo   \n426878  wyoming  https://wyoming.craigslist.org  28990  2018.0          lexus   \n\n                              model  condition    cylinders  ...       size  \\\n31                        f-150 xlt  excellent  6 cylinders  ...  full-size   \n32      sierra 2500 hd extended cab       good  8 cylinders  ...        NaN   \n33            silverado 1500 double       good  6 cylinders  ...        NaN   \n34                           tacoma  excellent  6 cylinders  ...        NaN   \n35            colorado extended cab       good  6 cylinders  ...        NaN   \n...                             ...        ...          ...  ...        ...   \n426872                c-class c 300       good          NaN  ...        NaN   \n426873                glc 300 sport       good          NaN  ...        NaN   \n426874              gs 350 sedan 4d       good  6 cylinders  ...        NaN   \n426876     s60 t5 momentum sedan 4d       good          NaN  ...        NaN   \n426878              es 350 sedan 4d       good  6 cylinders  ...        NaN   \n\n          type paint_color                                          image_url  \\\n31       truck       black  https://images.craigslist.org/00404_l4loxHvdQe...   \n32      pickup       black  https://images.craigslist.org/00V0V_ftJbKrOgdi...   \n33      pickup      silver  https://images.craigslist.org/00E0E_iKN07Sh7ou...   \n34       truck        grey  https://images.craigslist.org/00101_dXoZTH7iVm...   \n35      pickup         red  https://images.craigslist.org/00N0N_1xMPvfxRAI...   \n...        ...         ...                                                ...   \n426872   sedan       white  https://images.craigslist.org/00808_bYj0inoZ58...   \n426873   other       white  https://images.craigslist.org/00Q0Q_9VUbj91fKb...   \n426874   sedan       white  https://images.craigslist.org/00I0I_hJHfjCUppa...   \n426876   sedan         red  https://images.craigslist.org/00x0x_15sbgnxCIS...   \n426878   sedan      silver  https://images.craigslist.org/00z0z_bKnIVGLkDT...   \n\n                                              description county state  \\\n31      2013 F-150 XLT V6 4 Door. Good condition. Leve...    NaN    al   \n32      Carvana is the safer way to buy a car During t...    NaN    al   \n33      Carvana is the safer way to buy a car During t...    NaN    al   \n34      Selling my 2019 Toyota Tacoma TRD Off Road Dou...    NaN    al   \n35      Carvana is the safer way to buy a car During t...    NaN    al   \n...                                                   ...    ...   ...   \n426872  Carvana is the safer way to buy a car During t...    NaN    wy   \n426873  Carvana is the safer way to buy a car During t...    NaN    wy   \n426874  Carvana is the safer way to buy a car During t...    NaN    wy   \n426876  Carvana is the safer way to buy a car During t...    NaN    wy   \n426878  Carvana is the safer way to buy a car During t...    NaN    wy   \n\n              lat       long              posting_date  \n31      32.592000 -85.518900  2021-05-03T14:02:03-0500  \n32      32.590000 -85.480000  2021-05-03T13:41:25-0500  \n33      32.590000 -85.480000  2021-05-03T12:41:33-0500  \n34      32.601300 -85.443974  2021-05-03T12:12:59-0500  \n35      32.590000 -85.480000  2021-05-03T11:31:14-0500  \n...           ...        ...                       ...  \n426872  33.779214 -84.411811  2021-04-04T03:21:35-0600  \n426873  33.779214 -84.411811  2021-04-04T03:21:35-0600  \n426874  33.779214 -84.411811  2021-04-04T03:21:34-0600  \n426876  33.786500 -84.445400  2021-04-04T03:21:29-0600  \n426878  33.786500 -84.445400  2021-04-04T03:21:11-0600  \n\n[190785 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url</th>\n      <th>region</th>\n      <th>region_url</th>\n      <th>price</th>\n      <th>year</th>\n      <th>manufacturer</th>\n      <th>model</th>\n      <th>condition</th>\n      <th>cylinders</th>\n      <th>...</th>\n      <th>size</th>\n      <th>type</th>\n      <th>paint_color</th>\n      <th>image_url</th>\n      <th>description</th>\n      <th>county</th>\n      <th>state</th>\n      <th>lat</th>\n      <th>long</th>\n      <th>posting_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31</th>\n      <td>7316356412</td>\n      <td>https://auburn.craigslist.org/cto/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>15000</td>\n      <td>2013.0</td>\n      <td>ford</td>\n      <td>f-150 xlt</td>\n      <td>excellent</td>\n      <td>6 cylinders</td>\n      <td>...</td>\n      <td>full-size</td>\n      <td>truck</td>\n      <td>black</td>\n      <td>https://images.craigslist.org/00404_l4loxHvdQe...</td>\n      <td>2013 F-150 XLT V6 4 Door. Good condition. Leve...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.592000</td>\n      <td>-85.518900</td>\n      <td>2021-05-03T14:02:03-0500</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>7316343444</td>\n      <td>https://auburn.craigslist.org/ctd/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>27990</td>\n      <td>2012.0</td>\n      <td>gmc</td>\n      <td>sierra 2500 hd extended cab</td>\n      <td>good</td>\n      <td>8 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>pickup</td>\n      <td>black</td>\n      <td>https://images.craigslist.org/00V0V_ftJbKrOgdi...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.590000</td>\n      <td>-85.480000</td>\n      <td>2021-05-03T13:41:25-0500</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>7316304717</td>\n      <td>https://auburn.craigslist.org/ctd/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>34590</td>\n      <td>2016.0</td>\n      <td>chevrolet</td>\n      <td>silverado 1500 double</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>pickup</td>\n      <td>silver</td>\n      <td>https://images.craigslist.org/00E0E_iKN07Sh7ou...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.590000</td>\n      <td>-85.480000</td>\n      <td>2021-05-03T12:41:33-0500</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>7316285779</td>\n      <td>https://auburn.craigslist.org/cto/d/auburn-201...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>35000</td>\n      <td>2019.0</td>\n      <td>toyota</td>\n      <td>tacoma</td>\n      <td>excellent</td>\n      <td>6 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>truck</td>\n      <td>grey</td>\n      <td>https://images.craigslist.org/00101_dXoZTH7iVm...</td>\n      <td>Selling my 2019 Toyota Tacoma TRD Off Road Dou...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.601300</td>\n      <td>-85.443974</td>\n      <td>2021-05-03T12:12:59-0500</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>7316257769</td>\n      <td>https://auburn.craigslist.org/ctd/d/auburn-uni...</td>\n      <td>auburn</td>\n      <td>https://auburn.craigslist.org</td>\n      <td>29990</td>\n      <td>2016.0</td>\n      <td>chevrolet</td>\n      <td>colorado extended cab</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>pickup</td>\n      <td>red</td>\n      <td>https://images.craigslist.org/00N0N_1xMPvfxRAI...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>al</td>\n      <td>32.590000</td>\n      <td>-85.480000</td>\n      <td>2021-05-03T11:31:14-0500</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>426872</th>\n      <td>7301591201</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>32590</td>\n      <td>2020.0</td>\n      <td>mercedes-benz</td>\n      <td>c-class c 300</td>\n      <td>good</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>sedan</td>\n      <td>white</td>\n      <td>https://images.craigslist.org/00808_bYj0inoZ58...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.779214</td>\n      <td>-84.411811</td>\n      <td>2021-04-04T03:21:35-0600</td>\n    </tr>\n    <tr>\n      <th>426873</th>\n      <td>7301591202</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>30990</td>\n      <td>2018.0</td>\n      <td>mercedes-benz</td>\n      <td>glc 300 sport</td>\n      <td>good</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>other</td>\n      <td>white</td>\n      <td>https://images.craigslist.org/00Q0Q_9VUbj91fKb...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.779214</td>\n      <td>-84.411811</td>\n      <td>2021-04-04T03:21:35-0600</td>\n    </tr>\n    <tr>\n      <th>426874</th>\n      <td>7301591199</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>33590</td>\n      <td>2018.0</td>\n      <td>lexus</td>\n      <td>gs 350 sedan 4d</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>sedan</td>\n      <td>white</td>\n      <td>https://images.craigslist.org/00I0I_hJHfjCUppa...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.779214</td>\n      <td>-84.411811</td>\n      <td>2021-04-04T03:21:34-0600</td>\n    </tr>\n    <tr>\n      <th>426876</th>\n      <td>7301591187</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>30590</td>\n      <td>2020.0</td>\n      <td>volvo</td>\n      <td>s60 t5 momentum sedan 4d</td>\n      <td>good</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>sedan</td>\n      <td>red</td>\n      <td>https://images.craigslist.org/00x0x_15sbgnxCIS...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.786500</td>\n      <td>-84.445400</td>\n      <td>2021-04-04T03:21:29-0600</td>\n    </tr>\n    <tr>\n      <th>426878</th>\n      <td>7301591140</td>\n      <td>https://wyoming.craigslist.org/ctd/d/atlanta-2...</td>\n      <td>wyoming</td>\n      <td>https://wyoming.craigslist.org</td>\n      <td>28990</td>\n      <td>2018.0</td>\n      <td>lexus</td>\n      <td>es 350 sedan 4d</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>sedan</td>\n      <td>silver</td>\n      <td>https://images.craigslist.org/00z0z_bKnIVGLkDT...</td>\n      <td>Carvana is the safer way to buy a car During t...</td>\n      <td>NaN</td>\n      <td>wy</td>\n      <td>33.786500</td>\n      <td>-84.445400</td>\n      <td>2021-04-04T03:21:11-0600</td>\n    </tr>\n  </tbody>\n</table>\n<p>190785 rows × 26 columns</p>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_to_check = ['year', 'model', 'fuel', 'transmission', 'drive', 'type', 'paint_color']\n",
    "for column in row_to_check:\n",
    "    df = df[~df[column].isnull()]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "rm_brands = ['harley-davidson', 'alfa-romeo', 'datsun', 'tesla', 'land rover', 'porsche', 'aston-martin', 'ferrari']\n",
    "for brand in rm_brands:\n",
    "    df = df[~(df['manufacturer'] == brand)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "df = df.drop(  # ці ознаки ніяк не впливають на ціну, просто ссилки на зображення, id-шники, опис і тд\n",
    "    ['VIN', 'posting_date', 'id', 'size', 'url', 'region', 'region_url', 'state', 'title_status', 'image_url', 'lat',\n",
    "     'long',\n",
    "     'description', 'county'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "f-150                    4056\nsilverado 1500           2609\n1500                     1851\ncamry                    1563\nsilverado                1467\n                         ... \ncts sedan 4d               51\nrabbit                     51\ncorvette stingray z51      51\nf-450                      51\ngx 460                     51\nName: model, Length: 603, dtype: int64"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby('model').filter(lambda x: len(\n",
    "    x) > 50)  # виробники з малою к-стю лотів не сильно інформативні для моделей, в силу малої вибірки авто\n",
    "df['model'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "        price    year manufacturer                        model  condition  \\\n31      15000  2013.0         ford                    f-150 xlt  excellent   \n32      27990  2012.0          gmc  sierra 2500 hd extended cab       good   \n33      34590  2016.0    chevrolet        silverado 1500 double       good   \n34      35000  2019.0       toyota                       tacoma  excellent   \n35      29990  2016.0    chevrolet        colorado extended cab       good   \n...       ...     ...          ...                          ...        ...   \n426863  25590  2017.0         null     Genesis G80 3.8 Sedan 4D       good   \n426869  13990  2016.0         null        Scion iM Hatchback 4D       good   \n426870  22990  2020.0      hyundai           sonata se sedan 4d       good   \n426874  33590  2018.0        lexus              gs 350 sedan 4d       good   \n426878  28990  2018.0        lexus              es 350 sedan 4d       good   \n\n          cylinders   fuel  odometer transmission drive       type paint_color  \n31      6 cylinders    gas  128000.0    automatic   rwd      truck       black  \n32      8 cylinders    gas   68696.0        other   4wd     pickup       black  \n33      6 cylinders    gas   29499.0        other   4wd     pickup      silver  \n34      6 cylinders    gas   43000.0    automatic   4wd      truck        grey  \n35      6 cylinders    gas   17302.0        other   4wd     pickup         red  \n...             ...    ...       ...          ...   ...        ...         ...  \n426863  6 cylinders    gas   37608.0    automatic   rwd      sedan       white  \n426869         null  other   75626.0        other   fwd  hatchback       white  \n426870         null    gas    3066.0        other   fwd      sedan        blue  \n426874  6 cylinders    gas   30814.0    automatic   rwd      sedan       white  \n426878  6 cylinders    gas   30112.0        other   fwd      sedan      silver  \n\n[122436 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>year</th>\n      <th>manufacturer</th>\n      <th>model</th>\n      <th>condition</th>\n      <th>cylinders</th>\n      <th>fuel</th>\n      <th>odometer</th>\n      <th>transmission</th>\n      <th>drive</th>\n      <th>type</th>\n      <th>paint_color</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31</th>\n      <td>15000</td>\n      <td>2013.0</td>\n      <td>ford</td>\n      <td>f-150 xlt</td>\n      <td>excellent</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>128000.0</td>\n      <td>automatic</td>\n      <td>rwd</td>\n      <td>truck</td>\n      <td>black</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>27990</td>\n      <td>2012.0</td>\n      <td>gmc</td>\n      <td>sierra 2500 hd extended cab</td>\n      <td>good</td>\n      <td>8 cylinders</td>\n      <td>gas</td>\n      <td>68696.0</td>\n      <td>other</td>\n      <td>4wd</td>\n      <td>pickup</td>\n      <td>black</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>34590</td>\n      <td>2016.0</td>\n      <td>chevrolet</td>\n      <td>silverado 1500 double</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>29499.0</td>\n      <td>other</td>\n      <td>4wd</td>\n      <td>pickup</td>\n      <td>silver</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>35000</td>\n      <td>2019.0</td>\n      <td>toyota</td>\n      <td>tacoma</td>\n      <td>excellent</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>43000.0</td>\n      <td>automatic</td>\n      <td>4wd</td>\n      <td>truck</td>\n      <td>grey</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>29990</td>\n      <td>2016.0</td>\n      <td>chevrolet</td>\n      <td>colorado extended cab</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>17302.0</td>\n      <td>other</td>\n      <td>4wd</td>\n      <td>pickup</td>\n      <td>red</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>426863</th>\n      <td>25590</td>\n      <td>2017.0</td>\n      <td>null</td>\n      <td>Genesis G80 3.8 Sedan 4D</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>37608.0</td>\n      <td>automatic</td>\n      <td>rwd</td>\n      <td>sedan</td>\n      <td>white</td>\n    </tr>\n    <tr>\n      <th>426869</th>\n      <td>13990</td>\n      <td>2016.0</td>\n      <td>null</td>\n      <td>Scion iM Hatchback 4D</td>\n      <td>good</td>\n      <td>null</td>\n      <td>other</td>\n      <td>75626.0</td>\n      <td>other</td>\n      <td>fwd</td>\n      <td>hatchback</td>\n      <td>white</td>\n    </tr>\n    <tr>\n      <th>426870</th>\n      <td>22990</td>\n      <td>2020.0</td>\n      <td>hyundai</td>\n      <td>sonata se sedan 4d</td>\n      <td>good</td>\n      <td>null</td>\n      <td>gas</td>\n      <td>3066.0</td>\n      <td>other</td>\n      <td>fwd</td>\n      <td>sedan</td>\n      <td>blue</td>\n    </tr>\n    <tr>\n      <th>426874</th>\n      <td>33590</td>\n      <td>2018.0</td>\n      <td>lexus</td>\n      <td>gs 350 sedan 4d</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>30814.0</td>\n      <td>automatic</td>\n      <td>rwd</td>\n      <td>sedan</td>\n      <td>white</td>\n    </tr>\n    <tr>\n      <th>426878</th>\n      <td>28990</td>\n      <td>2018.0</td>\n      <td>lexus</td>\n      <td>es 350 sedan 4d</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>30112.0</td>\n      <td>other</td>\n      <td>fwd</td>\n      <td>sedan</td>\n      <td>silver</td>\n    </tr>\n  </tbody>\n</table>\n<p>122436 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.replace(np.nan, 'null',\n",
    "                regex=True)  # В деяких записах наявна більшість потрібних ознак, крім manufacturer, cylinders, condition, можна замінити на любу іншу назву по типу other\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "        price    year manufacturer                        model  condition  \\\n31      15000  2013.0         ford                    f-150 xlt  excellent   \n32      27990  2012.0          gmc  sierra 2500 hd extended cab       good   \n33      34590  2016.0    chevrolet        silverado 1500 double       good   \n34      35000  2019.0       toyota                       tacoma  excellent   \n35      29990  2016.0    chevrolet        colorado extended cab       good   \n...       ...     ...          ...                          ...        ...   \n426863  25590  2017.0         null     Genesis G80 3.8 Sedan 4D       good   \n426869  13990  2016.0         null        Scion iM Hatchback 4D       good   \n426870  22990  2020.0      hyundai           sonata se sedan 4d       good   \n426874  33590  2018.0        lexus              gs 350 sedan 4d       good   \n426878  28990  2018.0        lexus              es 350 sedan 4d       good   \n\n          cylinders   fuel  odometer transmission drive       type paint_color  \n31      6 cylinders    gas  128000.0    automatic   rwd      truck       black  \n32      8 cylinders    gas   68696.0        other   4wd     pickup       black  \n33      6 cylinders    gas   29499.0        other   4wd     pickup      silver  \n34      6 cylinders    gas   43000.0    automatic   4wd      truck        grey  \n35      6 cylinders    gas   17302.0        other   4wd     pickup         red  \n...             ...    ...       ...          ...   ...        ...         ...  \n426863  6 cylinders    gas   37608.0    automatic   rwd      sedan       white  \n426869         null  other   75626.0        other   fwd  hatchback       white  \n426870         null    gas    3066.0        other   fwd      sedan        blue  \n426874  6 cylinders    gas   30814.0    automatic   rwd      sedan       white  \n426878  6 cylinders    gas   30112.0        other   fwd      sedan      silver  \n\n[122436 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>year</th>\n      <th>manufacturer</th>\n      <th>model</th>\n      <th>condition</th>\n      <th>cylinders</th>\n      <th>fuel</th>\n      <th>odometer</th>\n      <th>transmission</th>\n      <th>drive</th>\n      <th>type</th>\n      <th>paint_color</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31</th>\n      <td>15000</td>\n      <td>2013.0</td>\n      <td>ford</td>\n      <td>f-150 xlt</td>\n      <td>excellent</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>128000.0</td>\n      <td>automatic</td>\n      <td>rwd</td>\n      <td>truck</td>\n      <td>black</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>27990</td>\n      <td>2012.0</td>\n      <td>gmc</td>\n      <td>sierra 2500 hd extended cab</td>\n      <td>good</td>\n      <td>8 cylinders</td>\n      <td>gas</td>\n      <td>68696.0</td>\n      <td>other</td>\n      <td>4wd</td>\n      <td>pickup</td>\n      <td>black</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>34590</td>\n      <td>2016.0</td>\n      <td>chevrolet</td>\n      <td>silverado 1500 double</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>29499.0</td>\n      <td>other</td>\n      <td>4wd</td>\n      <td>pickup</td>\n      <td>silver</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>35000</td>\n      <td>2019.0</td>\n      <td>toyota</td>\n      <td>tacoma</td>\n      <td>excellent</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>43000.0</td>\n      <td>automatic</td>\n      <td>4wd</td>\n      <td>truck</td>\n      <td>grey</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>29990</td>\n      <td>2016.0</td>\n      <td>chevrolet</td>\n      <td>colorado extended cab</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>17302.0</td>\n      <td>other</td>\n      <td>4wd</td>\n      <td>pickup</td>\n      <td>red</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>426863</th>\n      <td>25590</td>\n      <td>2017.0</td>\n      <td>null</td>\n      <td>Genesis G80 3.8 Sedan 4D</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>37608.0</td>\n      <td>automatic</td>\n      <td>rwd</td>\n      <td>sedan</td>\n      <td>white</td>\n    </tr>\n    <tr>\n      <th>426869</th>\n      <td>13990</td>\n      <td>2016.0</td>\n      <td>null</td>\n      <td>Scion iM Hatchback 4D</td>\n      <td>good</td>\n      <td>null</td>\n      <td>other</td>\n      <td>75626.0</td>\n      <td>other</td>\n      <td>fwd</td>\n      <td>hatchback</td>\n      <td>white</td>\n    </tr>\n    <tr>\n      <th>426870</th>\n      <td>22990</td>\n      <td>2020.0</td>\n      <td>hyundai</td>\n      <td>sonata se sedan 4d</td>\n      <td>good</td>\n      <td>null</td>\n      <td>gas</td>\n      <td>3066.0</td>\n      <td>other</td>\n      <td>fwd</td>\n      <td>sedan</td>\n      <td>blue</td>\n    </tr>\n    <tr>\n      <th>426874</th>\n      <td>33590</td>\n      <td>2018.0</td>\n      <td>lexus</td>\n      <td>gs 350 sedan 4d</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>30814.0</td>\n      <td>automatic</td>\n      <td>rwd</td>\n      <td>sedan</td>\n      <td>white</td>\n    </tr>\n    <tr>\n      <th>426878</th>\n      <td>28990</td>\n      <td>2018.0</td>\n      <td>lexus</td>\n      <td>es 350 sedan 4d</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>30112.0</td>\n      <td>other</td>\n      <td>fwd</td>\n      <td>sedan</td>\n      <td>silver</td>\n    </tr>\n  </tbody>\n</table>\n<p>122436 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "price           0\nyear            0\nmanufacturer    0\nmodel           0\ncondition       0\ncylinders       0\nfuel            0\nodometer        0\ntransmission    0\ndrive           0\ntype            0\npaint_color     0\ndtype: int64"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_v.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Щоб не ранити весь код зверху, можна загрузити препроцеснутий датасет\n",
    "df = pd.read_csv('preprocessed_v.csv')\n",
    "df = df.replace(np.nan, 'null', regex=True)\n",
    "df = df.drop(columns='Unnamed: 0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(122436, 12)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data = df[df.columns]\n",
    "encoded_data = encoded_data.dropna()\n",
    "encoded_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "        price      year manufacturer                        model  condition  \\\n0       15000  0.141352         ford                    f-150 xlt  excellent   \n1       27990 -0.024487          gmc  sierra 2500 hd extended cab       good   \n2       34590  0.638869    chevrolet        silverado 1500 double       good   \n3       35000  1.136385       toyota                       tacoma  excellent   \n4       29990  0.638869    chevrolet        colorado extended cab       good   \n...       ...       ...          ...                          ...        ...   \n122431  25590  0.804708         null     Genesis G80 3.8 Sedan 4D       good   \n122432  13990  0.638869         null        Scion iM Hatchback 4D       good   \n122433  22990  1.302224      hyundai           sonata se sedan 4d       good   \n122434  33590  0.970546        lexus              gs 350 sedan 4d       good   \n122435  28990  0.970546        lexus              es 350 sedan 4d       good   \n\n          cylinders   fuel  odometer transmission drive       type paint_color  \n0       6 cylinders    gas  0.272400    automatic   rwd      truck       black  \n1       8 cylinders    gas -0.279794        other   4wd     pickup       black  \n2       6 cylinders    gas -0.644768        other   4wd     pickup      silver  \n3       6 cylinders    gas -0.519057    automatic   4wd      truck        grey  \n4       6 cylinders    gas -0.758337        other   4wd     pickup         red  \n...             ...    ...       ...          ...   ...        ...         ...  \n122431  6 cylinders    gas -0.569263    automatic   rwd      sedan       white  \n122432         null  other -0.215267        other   fwd  hatchback       white  \n122433         null    gas -0.890892        other   fwd      sedan        blue  \n122434  6 cylinders    gas -0.632524    automatic   rwd      sedan       white  \n122435  6 cylinders    gas -0.639060        other   fwd      sedan      silver  \n\n[122436 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>year</th>\n      <th>manufacturer</th>\n      <th>model</th>\n      <th>condition</th>\n      <th>cylinders</th>\n      <th>fuel</th>\n      <th>odometer</th>\n      <th>transmission</th>\n      <th>drive</th>\n      <th>type</th>\n      <th>paint_color</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15000</td>\n      <td>0.141352</td>\n      <td>ford</td>\n      <td>f-150 xlt</td>\n      <td>excellent</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>0.272400</td>\n      <td>automatic</td>\n      <td>rwd</td>\n      <td>truck</td>\n      <td>black</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>27990</td>\n      <td>-0.024487</td>\n      <td>gmc</td>\n      <td>sierra 2500 hd extended cab</td>\n      <td>good</td>\n      <td>8 cylinders</td>\n      <td>gas</td>\n      <td>-0.279794</td>\n      <td>other</td>\n      <td>4wd</td>\n      <td>pickup</td>\n      <td>black</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34590</td>\n      <td>0.638869</td>\n      <td>chevrolet</td>\n      <td>silverado 1500 double</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>-0.644768</td>\n      <td>other</td>\n      <td>4wd</td>\n      <td>pickup</td>\n      <td>silver</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35000</td>\n      <td>1.136385</td>\n      <td>toyota</td>\n      <td>tacoma</td>\n      <td>excellent</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>-0.519057</td>\n      <td>automatic</td>\n      <td>4wd</td>\n      <td>truck</td>\n      <td>grey</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29990</td>\n      <td>0.638869</td>\n      <td>chevrolet</td>\n      <td>colorado extended cab</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>-0.758337</td>\n      <td>other</td>\n      <td>4wd</td>\n      <td>pickup</td>\n      <td>red</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>122431</th>\n      <td>25590</td>\n      <td>0.804708</td>\n      <td>null</td>\n      <td>Genesis G80 3.8 Sedan 4D</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>-0.569263</td>\n      <td>automatic</td>\n      <td>rwd</td>\n      <td>sedan</td>\n      <td>white</td>\n    </tr>\n    <tr>\n      <th>122432</th>\n      <td>13990</td>\n      <td>0.638869</td>\n      <td>null</td>\n      <td>Scion iM Hatchback 4D</td>\n      <td>good</td>\n      <td>null</td>\n      <td>other</td>\n      <td>-0.215267</td>\n      <td>other</td>\n      <td>fwd</td>\n      <td>hatchback</td>\n      <td>white</td>\n    </tr>\n    <tr>\n      <th>122433</th>\n      <td>22990</td>\n      <td>1.302224</td>\n      <td>hyundai</td>\n      <td>sonata se sedan 4d</td>\n      <td>good</td>\n      <td>null</td>\n      <td>gas</td>\n      <td>-0.890892</td>\n      <td>other</td>\n      <td>fwd</td>\n      <td>sedan</td>\n      <td>blue</td>\n    </tr>\n    <tr>\n      <th>122434</th>\n      <td>33590</td>\n      <td>0.970546</td>\n      <td>lexus</td>\n      <td>gs 350 sedan 4d</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>-0.632524</td>\n      <td>automatic</td>\n      <td>rwd</td>\n      <td>sedan</td>\n      <td>white</td>\n    </tr>\n    <tr>\n      <th>122435</th>\n      <td>28990</td>\n      <td>0.970546</td>\n      <td>lexus</td>\n      <td>es 350 sedan 4d</td>\n      <td>good</td>\n      <td>6 cylinders</td>\n      <td>gas</td>\n      <td>-0.639060</td>\n      <td>other</td>\n      <td>fwd</td>\n      <td>sedan</td>\n      <td>silver</td>\n    </tr>\n  </tbody>\n</table>\n<p>122436 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scalers = [StandardScaler(), StandardScaler()]\n",
    "\n",
    "encoded_data['year'] = scalers[0].fit_transform(encoded_data['year'].values.reshape(-1, 1))\n",
    "encoded_data['odometer'] = scalers[1].fit_transform(encoded_data['odometer'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "encoded_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoded_data =pd.get_dummies(encoded_data, dummy_na=True, columns = ['manufacturer', 'fuel','condition','drive','cylinders','transmission','type','paint_color'])\n",
    "encoders = []\n",
    "\n",
    "encoded_data['model'] = LabelEncoder().fit_transform(encoded_data['model'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "        price      year  model  odometer  manufacturer_acura  \\\n0       15000  0.141352    226  0.272400                   0   \n1       27990 -0.024487    469 -0.279794                   0   \n2       34590  0.638869    476 -0.644768                   0   \n3       35000  1.136385    521 -0.519057                   0   \n4       29990  0.638869    122 -0.758337                   0   \n...       ...       ...    ...       ...                 ...   \n122431  25590  0.804708     44 -0.569263                   0   \n122432  13990  0.638869     48 -0.215267                   0   \n122433  22990  1.302224    497 -0.890892                   0   \n122434  33590  0.970546    309 -0.632524                   0   \n122435  28990  0.970546    202 -0.639060                   0   \n\n        manufacturer_audi  manufacturer_bmw  manufacturer_buick  \\\n0                       0                 0                   0   \n1                       0                 0                   0   \n2                       0                 0                   0   \n3                       0                 0                   0   \n4                       0                 0                   0   \n...                   ...               ...                 ...   \n122431                  0                 0                   0   \n122432                  0                 0                   0   \n122433                  0                 0                   0   \n122434                  0                 0                   0   \n122435                  0                 0                   0   \n\n        manufacturer_cadillac  manufacturer_chevrolet  ...  \\\n0                           0                       0  ...   \n1                           0                       0  ...   \n2                           0                       1  ...   \n3                           0                       0  ...   \n4                           0                       1  ...   \n...                       ...                     ...  ...   \n122431                      0                       0  ...   \n122432                      0                       0  ...   \n122433                      0                       0  ...   \n122434                      0                       0  ...   \n122435                      0                       0  ...   \n\n        paint_color_custom  paint_color_green  paint_color_grey  \\\n0                        0                  0                 0   \n1                        0                  0                 0   \n2                        0                  0                 0   \n3                        0                  0                 1   \n4                        0                  0                 0   \n...                    ...                ...               ...   \n122431                   0                  0                 0   \n122432                   0                  0                 0   \n122433                   0                  0                 0   \n122434                   0                  0                 0   \n122435                   0                  0                 0   \n\n        paint_color_orange  paint_color_purple  paint_color_red  \\\n0                        0                   0                0   \n1                        0                   0                0   \n2                        0                   0                0   \n3                        0                   0                0   \n4                        0                   0                1   \n...                    ...                 ...              ...   \n122431                   0                   0                0   \n122432                   0                   0                0   \n122433                   0                   0                0   \n122434                   0                   0                0   \n122435                   0                   0                0   \n\n        paint_color_silver  paint_color_white  paint_color_yellow  \\\n0                        0                  0                   0   \n1                        0                  0                   0   \n2                        1                  0                   0   \n3                        0                  0                   0   \n4                        0                  0                   0   \n...                    ...                ...                 ...   \n122431                   0                  1                   0   \n122432                   0                  1                   0   \n122433                   0                  0                   0   \n122434                   0                  1                   0   \n122435                   1                  0                   0   \n\n        paint_color_nan  \n0                     0  \n1                     0  \n2                     0  \n3                     0  \n4                     0  \n...                 ...  \n122431                0  \n122432                0  \n122433                0  \n122434                0  \n122435                0  \n\n[122436 rows x 98 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>year</th>\n      <th>model</th>\n      <th>odometer</th>\n      <th>manufacturer_acura</th>\n      <th>manufacturer_audi</th>\n      <th>manufacturer_bmw</th>\n      <th>manufacturer_buick</th>\n      <th>manufacturer_cadillac</th>\n      <th>manufacturer_chevrolet</th>\n      <th>...</th>\n      <th>paint_color_custom</th>\n      <th>paint_color_green</th>\n      <th>paint_color_grey</th>\n      <th>paint_color_orange</th>\n      <th>paint_color_purple</th>\n      <th>paint_color_red</th>\n      <th>paint_color_silver</th>\n      <th>paint_color_white</th>\n      <th>paint_color_yellow</th>\n      <th>paint_color_nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15000</td>\n      <td>0.141352</td>\n      <td>226</td>\n      <td>0.272400</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>27990</td>\n      <td>-0.024487</td>\n      <td>469</td>\n      <td>-0.279794</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34590</td>\n      <td>0.638869</td>\n      <td>476</td>\n      <td>-0.644768</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35000</td>\n      <td>1.136385</td>\n      <td>521</td>\n      <td>-0.519057</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29990</td>\n      <td>0.638869</td>\n      <td>122</td>\n      <td>-0.758337</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>122431</th>\n      <td>25590</td>\n      <td>0.804708</td>\n      <td>44</td>\n      <td>-0.569263</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>122432</th>\n      <td>13990</td>\n      <td>0.638869</td>\n      <td>48</td>\n      <td>-0.215267</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>122433</th>\n      <td>22990</td>\n      <td>1.302224</td>\n      <td>497</td>\n      <td>-0.890892</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>122434</th>\n      <td>33590</td>\n      <td>0.970546</td>\n      <td>309</td>\n      <td>-0.632524</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>122435</th>\n      <td>28990</td>\n      <td>0.970546</td>\n      <td>202</td>\n      <td>-0.639060</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>122436 rows × 98 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df_for_1_model = encoded_data.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "(24488,)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = encoded_data.drop(columns=['price'], axis=1)\n",
    "y_train = encoded_data['price']\n",
    "X_train, X_test, y_train, y_test = split(X_train, y_train, train_size=0.8, random_state=18)\n",
    "y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Lambda, BatchNormalization\n",
    "\n",
    "size = 97\n",
    "def residual_block(x):\n",
    "  y = Dense(size, activation='relu')(x)\n",
    "  for i in range (0,3):\n",
    "      y = Dense(size, activation='relu')(y)\n",
    "  y = tf.keras.layers.Add()([x, y])\n",
    "  return y\n",
    "\n",
    "def self_attention(x):\n",
    "  \"\"\"A self-attention layer.\"\"\"\n",
    "  q = Dense(size, activation='tanh')(x)\n",
    "  k = Dense(size, activation='tanh')(x)\n",
    "  v = Dense(size, activation='tanh')(x)\n",
    "  a = Lambda(lambda x: tf.matmul(x[0], x[1], transpose_b=True))(\n",
    "      [q, k])\n",
    "  a = tf.nn.softmax(a, axis=-1)\n",
    "  y = Lambda(lambda x: tf.matmul(x[0], x[1]))([a, v])\n",
    "  return y\n",
    "inputs = tf.keras.layers.Input(shape=(size,))\n",
    "\n",
    "# Residual blocks\n",
    "\n",
    "x = residual_block(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = residual_block(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = self_attention(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = residual_block(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = residual_block(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = self_attention(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Dropout\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(1)(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='rmsprop', loss='mse')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3048/3061 [============================>.] - ETA: 0s - loss: 450283072.0000WARNING:tensorflow:Can save best model only with mse available, skipping.\n",
      "3061/3061 [==============================] - 16s 4ms/step - loss: 450122528.0000 - val_loss: 452978464.0000\n",
      "Epoch 2/10\n",
      "3047/3061 [============================>.] - ETA: 0s - loss: 353275104.0000WARNING:tensorflow:Can save best model only with mse available, skipping.\n",
      "3061/3061 [==============================] - 11s 4ms/step - loss: 352954944.0000 - val_loss: 303549728.0000\n",
      "Epoch 3/10\n",
      "3048/3061 [============================>.] - ETA: 0s - loss: 206611472.0000WARNING:tensorflow:Can save best model only with mse available, skipping.\n",
      "3061/3061 [==============================] - 10s 3ms/step - loss: 206314848.0000 - val_loss: 165872064.0000\n",
      "Epoch 4/10\n",
      "3052/3061 [============================>.] - ETA: 0s - loss: 83233328.0000WARNING:tensorflow:Can save best model only with mse available, skipping.\n",
      "3061/3061 [==============================] - 11s 4ms/step - loss: 83113672.0000 - val_loss: 35528444.0000\n",
      "Epoch 5/10\n",
      "3046/3061 [============================>.] - ETA: 0s - loss: 32235138.0000WARNING:tensorflow:Can save best model only with mse available, skipping.\n",
      "3061/3061 [==============================] - 11s 4ms/step - loss: 32229568.0000 - val_loss: 44852176.0000\n",
      "Epoch 6/10\n",
      "3061/3061 [==============================] - ETA: 0s - loss: 26786624.0000WARNING:tensorflow:Can save best model only with mse available, skipping.\n",
      "3061/3061 [==============================] - 11s 4ms/step - loss: 26786624.0000 - val_loss: 35534636.0000\n",
      "Epoch 7/10\n",
      "3050/3061 [============================>.] - ETA: 0s - loss: 25501296.0000WARNING:tensorflow:Can save best model only with mse available, skipping.\n",
      "3061/3061 [==============================] - 11s 4ms/step - loss: 25501368.0000 - val_loss: 40027168.0000\n",
      "Epoch 8/10\n",
      "3057/3061 [============================>.] - ETA: 0s - loss: 25227890.0000WARNING:tensorflow:Can save best model only with mse available, skipping.\n",
      "3061/3061 [==============================] - 10s 3ms/step - loss: 25219602.0000 - val_loss: 58310248.0000\n",
      "Epoch 9/10\n",
      "3056/3061 [============================>.] - ETA: 0s - loss: 24067290.0000WARNING:tensorflow:Can save best model only with mse available, skipping.\n",
      "3061/3061 [==============================] - 10s 3ms/step - loss: 24078730.0000 - val_loss: 54172484.0000\n",
      "Epoch 10/10\n",
      "3052/3061 [============================>.] - ETA: 0s - loss: 24184738.0000WARNING:tensorflow:Can save best model only with mse available, skipping.\n",
      "3061/3061 [==============================] - 10s 3ms/step - loss: 24185216.0000 - val_loss: 60291268.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.version_utils import callbacks\n",
    "from matplotlib import pyplot as plt\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "        './tmp/checkpoint', save_format='tf', monitor='mse',verbose=0, save_best_only=True, save_weights_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[checkpoint,early_stopping],\n",
    "                    verbose=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='valid')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "model.save('resnet.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766/766 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3061/3061 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared value of test data:  0.5924913116811347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "print(\"R Squared value of test data: \",r2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared value of test data:  0.5818107864123601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print(\"R Squared value of test data: \",r2_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "21645      5000\n6358       4000\n25298     11988\n64343     18933\n112680    38590\n          ...  \n5424      10500\n24365     20561\n17301      2995\n30378     11988\n72145      2999\nName: price, Length: 24488, dtype: int64"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[16159.773],\n       [15606.502],\n       [16424.123],\n       ...,\n       [22920.537],\n       [22920.535],\n       [22920.537]], dtype=float32)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "X_train.insert(0, 'pre_result', y_pred_train)\n",
    "X_test.insert(0, 'pre_result', y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "X_train.to_csv('train_with_pre.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "X_test.to_csv('test_with_pre.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "         pre_result      year  model  odometer  manufacturer_acura  \\\n21500  12441.706055 -1.185358     56  0.235155                   0   \n9777   23350.601562  1.468063    390 -0.878499                   0   \n32800  18809.992188  0.970546    498 -0.763114                   0   \n8101   13941.604492 -1.848714    459  0.398829                   0   \n2375   14629.379883  0.638869    389 -0.249030                   0   \n...             ...       ...    ...       ...                 ...   \n1726   27774.488281  0.307191    472 -0.189717                   0   \n35653  33022.308594  0.804708    224 -0.563015                   0   \n91256  16556.214844 -0.024487    258 -0.226124                   0   \n94483  19079.906250 -0.024487    479  0.296526                   0   \n60714  27879.365234  1.136385      1 -0.788701                   0   \n\n       manufacturer_audi  manufacturer_bmw  manufacturer_buick  \\\n21500                  1                 0                   0   \n9777                   0                 0                   0   \n32800                  0                 0                   0   \n8101                   0                 0                   0   \n2375                   0                 0                   0   \n...                  ...               ...                 ...   \n1726                   0                 0                   0   \n35653                  0                 0                   0   \n91256                  0                 0                   0   \n94483                  0                 0                   0   \n60714                  0                 0                   0   \n\n       manufacturer_cadillac  manufacturer_chevrolet  ...  paint_color_custom  \\\n21500                      0                       0  ...                   1   \n9777                       0                       0  ...                   0   \n32800                      0                       0  ...                   0   \n8101                       0                       0  ...                   0   \n2375                       0                       0  ...                   0   \n...                      ...                     ...  ...                 ...   \n1726                       0                       1  ...                   0   \n35653                      0                       0  ...                   0   \n91256                      0                       0  ...                   0   \n94483                      0                       1  ...                   0   \n60714                      0                       0  ...                   0   \n\n       paint_color_green  paint_color_grey  paint_color_orange  \\\n21500                  0                 0                   0   \n9777                   0                 0                   0   \n32800                  0                 0                   0   \n8101                   0                 0                   0   \n2375                   0                 0                   0   \n...                  ...               ...                 ...   \n1726                   0                 0                   0   \n35653                  0                 0                   0   \n91256                  0                 1                   0   \n94483                  0                 0                   0   \n60714                  0                 0                   0   \n\n       paint_color_purple  paint_color_red  paint_color_silver  \\\n21500                   0                0                   0   \n9777                    0                0                   1   \n32800                   0                0                   0   \n8101                    0                0                   0   \n2375                    0                0                   0   \n...                   ...              ...                 ...   \n1726                    0                0                   0   \n35653                   0                0                   0   \n91256                   0                0                   0   \n94483                   0                0                   0   \n60714                   0                1                   0   \n\n       paint_color_white  paint_color_yellow  paint_color_nan  \n21500                  0                   0                0  \n9777                   0                   0                0  \n32800                  1                   0                0  \n8101                   1                   0                0  \n2375                   0                   0                0  \n...                  ...                 ...              ...  \n1726                   0                   0                0  \n35653                  1                   0                0  \n91256                  0                   0                0  \n94483                  0                   0                0  \n60714                  0                   0                0  \n\n[97948 rows x 98 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pre_result</th>\n      <th>year</th>\n      <th>model</th>\n      <th>odometer</th>\n      <th>manufacturer_acura</th>\n      <th>manufacturer_audi</th>\n      <th>manufacturer_bmw</th>\n      <th>manufacturer_buick</th>\n      <th>manufacturer_cadillac</th>\n      <th>manufacturer_chevrolet</th>\n      <th>...</th>\n      <th>paint_color_custom</th>\n      <th>paint_color_green</th>\n      <th>paint_color_grey</th>\n      <th>paint_color_orange</th>\n      <th>paint_color_purple</th>\n      <th>paint_color_red</th>\n      <th>paint_color_silver</th>\n      <th>paint_color_white</th>\n      <th>paint_color_yellow</th>\n      <th>paint_color_nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21500</th>\n      <td>12441.706055</td>\n      <td>-1.185358</td>\n      <td>56</td>\n      <td>0.235155</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9777</th>\n      <td>23350.601562</td>\n      <td>1.468063</td>\n      <td>390</td>\n      <td>-0.878499</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32800</th>\n      <td>18809.992188</td>\n      <td>0.970546</td>\n      <td>498</td>\n      <td>-0.763114</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8101</th>\n      <td>13941.604492</td>\n      <td>-1.848714</td>\n      <td>459</td>\n      <td>0.398829</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2375</th>\n      <td>14629.379883</td>\n      <td>0.638869</td>\n      <td>389</td>\n      <td>-0.249030</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1726</th>\n      <td>27774.488281</td>\n      <td>0.307191</td>\n      <td>472</td>\n      <td>-0.189717</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35653</th>\n      <td>33022.308594</td>\n      <td>0.804708</td>\n      <td>224</td>\n      <td>-0.563015</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>91256</th>\n      <td>16556.214844</td>\n      <td>-0.024487</td>\n      <td>258</td>\n      <td>-0.226124</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>94483</th>\n      <td>19079.906250</td>\n      <td>-0.024487</td>\n      <td>479</td>\n      <td>0.296526</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>60714</th>\n      <td>27879.365234</td>\n      <td>1.136385</td>\n      <td>1</td>\n      <td>-0.788701</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>97948 rows × 98 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('train_with_pre.csv')\n",
    "X_train = X_train.drop(columns='Unnamed: 0')\n",
    "X_test = pd.read_csv('test_with_pre.csv')\n",
    "X_test = X_test.drop(columns='Unnamed: 0')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "       pre_result      year  model  odometer  manufacturer_acura  \\\n0      12441.7060 -1.185358     56  0.235155                   0   \n1      23350.6020  1.468063    390 -0.878499                   0   \n2      18809.9920  0.970546    498 -0.763114                   0   \n3      13941.6045 -1.848714    459  0.398829                   0   \n4      14629.3800  0.638869    389 -0.249030                   0   \n...           ...       ...    ...       ...                 ...   \n97943  27774.4880  0.307191    472 -0.189717                   0   \n97944  33022.3100  0.804708    224 -0.563015                   0   \n97945  16556.2150 -0.024487    258 -0.226124                   0   \n97946  19079.9060 -0.024487    479  0.296526                   0   \n97947  27879.3650  1.136385      1 -0.788701                   0   \n\n       manufacturer_audi  manufacturer_bmw  manufacturer_buick  \\\n0                      1                 0                   0   \n1                      0                 0                   0   \n2                      0                 0                   0   \n3                      0                 0                   0   \n4                      0                 0                   0   \n...                  ...               ...                 ...   \n97943                  0                 0                   0   \n97944                  0                 0                   0   \n97945                  0                 0                   0   \n97946                  0                 0                   0   \n97947                  0                 0                   0   \n\n       manufacturer_cadillac  manufacturer_chevrolet  ...  paint_color_custom  \\\n0                          0                       0  ...                   1   \n1                          0                       0  ...                   0   \n2                          0                       0  ...                   0   \n3                          0                       0  ...                   0   \n4                          0                       0  ...                   0   \n...                      ...                     ...  ...                 ...   \n97943                      0                       1  ...                   0   \n97944                      0                       0  ...                   0   \n97945                      0                       0  ...                   0   \n97946                      0                       1  ...                   0   \n97947                      0                       0  ...                   0   \n\n       paint_color_green  paint_color_grey  paint_color_orange  \\\n0                      0                 0                   0   \n1                      0                 0                   0   \n2                      0                 0                   0   \n3                      0                 0                   0   \n4                      0                 0                   0   \n...                  ...               ...                 ...   \n97943                  0                 0                   0   \n97944                  0                 0                   0   \n97945                  0                 1                   0   \n97946                  0                 0                   0   \n97947                  0                 0                   0   \n\n       paint_color_purple  paint_color_red  paint_color_silver  \\\n0                       0                0                   0   \n1                       0                0                   1   \n2                       0                0                   0   \n3                       0                0                   0   \n4                       0                0                   0   \n...                   ...              ...                 ...   \n97943                   0                0                   0   \n97944                   0                0                   0   \n97945                   0                0                   0   \n97946                   0                0                   0   \n97947                   0                1                   0   \n\n       paint_color_white  paint_color_yellow  paint_color_nan  \n0                      0                   0                0  \n1                      0                   0                0  \n2                      1                   0                0  \n3                      1                   0                0  \n4                      0                   0                0  \n...                  ...                 ...              ...  \n97943                  0                   0                0  \n97944                  1                   0                0  \n97945                  0                   0                0  \n97946                  0                   0                0  \n97947                  0                   0                0  \n\n[97948 rows x 98 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pre_result</th>\n      <th>year</th>\n      <th>model</th>\n      <th>odometer</th>\n      <th>manufacturer_acura</th>\n      <th>manufacturer_audi</th>\n      <th>manufacturer_bmw</th>\n      <th>manufacturer_buick</th>\n      <th>manufacturer_cadillac</th>\n      <th>manufacturer_chevrolet</th>\n      <th>...</th>\n      <th>paint_color_custom</th>\n      <th>paint_color_green</th>\n      <th>paint_color_grey</th>\n      <th>paint_color_orange</th>\n      <th>paint_color_purple</th>\n      <th>paint_color_red</th>\n      <th>paint_color_silver</th>\n      <th>paint_color_white</th>\n      <th>paint_color_yellow</th>\n      <th>paint_color_nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12441.7060</td>\n      <td>-1.185358</td>\n      <td>56</td>\n      <td>0.235155</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23350.6020</td>\n      <td>1.468063</td>\n      <td>390</td>\n      <td>-0.878499</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18809.9920</td>\n      <td>0.970546</td>\n      <td>498</td>\n      <td>-0.763114</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13941.6045</td>\n      <td>-1.848714</td>\n      <td>459</td>\n      <td>0.398829</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14629.3800</td>\n      <td>0.638869</td>\n      <td>389</td>\n      <td>-0.249030</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>97943</th>\n      <td>27774.4880</td>\n      <td>0.307191</td>\n      <td>472</td>\n      <td>-0.189717</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97944</th>\n      <td>33022.3100</td>\n      <td>0.804708</td>\n      <td>224</td>\n      <td>-0.563015</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97945</th>\n      <td>16556.2150</td>\n      <td>-0.024487</td>\n      <td>258</td>\n      <td>-0.226124</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97946</th>\n      <td>19079.9060</td>\n      <td>-0.024487</td>\n      <td>479</td>\n      <td>0.296526</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97947</th>\n      <td>27879.3650</td>\n      <td>1.136385</td>\n      <td>1</td>\n      <td>-0.788701</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>97948 rows × 98 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from keras.metrics import metrics\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators':150,\n",
    "    'learning_rate':0.1,\n",
    "    'gamma':0,\n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.9,\n",
    "    'max_depth':8\n",
    "}\n",
    "\n",
    "lgbm_params ={\n",
    "    'feature_fraction':0.8,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq':2,\n",
    "    'num_leaves':32\n",
    "}\n",
    "def MAPE_metric(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "def MAE_metric(y_true, y_pred):\n",
    "    return metrics.mean_absolute_error(y_true, y_pred)\n",
    "def Accuracy_metric(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    mape = sum(np.abs((y_true - y_pred)/y_true))/n\n",
    "    alpha = pd.DataFrame(abs(y_true - y_pred)/y_true)\n",
    "    Accuracy = (alpha[alpha <= 0.05].count() /alpha.count())*0.8+0.2*(1-mape)\n",
    "    return np.float(Accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def train_xgb(x_train_f, y_train_f,x_test_f,y_test_f, params):\n",
    "    mdl = xgb.XGBRegressor(**params)\n",
    "    mdl.fit(x_train_f, y_train_f)\n",
    "    y_pred_test = mdl.predict(x_test_f)\n",
    "    y_pred_train_f = mdl.predict(x_train_f)\n",
    "    x_train_f['pre_result'] = y_pred_train_f\n",
    "    x_test_f['pre_result'] = y_pred_test\n",
    "    return MAPE_metric(y_test_f, y_pred_test), Accuracy_metric(y_test_f, y_pred_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "def train_lgbm(x_train_f, y_train_f,x_test_f,y_test_f, params):\n",
    "    mdl = LGBMRegressor(**params)\n",
    "    mdl.fit(x_train_f, y_train_f)\n",
    "    y_pred_test = mdl.predict(x_test_f)\n",
    "    y_pred_train = mdl.predict(x_train_f)\n",
    "\n",
    "    x_train_f['pre_result'] = y_pred_train\n",
    "    x_test_f['pre_result'] = y_pred_test\n",
    "    return MAPE_metric(y_test_f, y_pred_test), Accuracy_metric(y_test_f, y_pred_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def vizualize(x,y):\n",
    "    plt.plot(x,y)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "\n",
    "# global index\n",
    "# index = 1\n",
    "def use_XGB_LGBM_framework(x_train_f,y_train_f,x_test_f,y_test_f):\n",
    "    min_loss = np.inf\n",
    "    acc_res = []\n",
    "    max_acc = 0\n",
    "    loss = 1000000000000\n",
    "    # while loss < min_loss:\n",
    "    for index in range(1,30):\n",
    "        print(\"loss= \"+str(loss))\n",
    "        print(\"min_loss= \"+str(min_loss))\n",
    "        min_loss = loss\n",
    "        if index%2==1:\n",
    "            loss, acc = train_xgb(x_train_f, y_train_f,x_test_f,y_test_f, xgb_params)\n",
    "        else:\n",
    "            loss,acc = train_lgbm(x_train_f, y_train_f,x_test_f, y_test_f, lgbm_params)\n",
    "        acc_res.append(acc)\n",
    "    enum = range(1, len(acc_res)+1)\n",
    "    if acc > max_acc:\n",
    "        max_acc = acc\n",
    "    acc_res\n",
    "\n",
    "    return enum,acc_res,max_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 1000000000000\n",
      "min_loss= inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Study\\8_term\\Comp_vision\\L1\\venv\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 19.411910036817368\n",
      "min_loss= 1000000000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 18.559292162546946\n",
      "min_loss= 19.411910036817368\n",
      "loss= 15.16496971415128\n",
      "min_loss= 18.559292162546946\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 14.897624261593146\n",
      "min_loss= 15.16496971415128\n",
      "loss= 12.682161409818512\n",
      "min_loss= 14.897624261593146\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 12.625908963969925\n",
      "min_loss= 12.682161409818512\n",
      "loss= 11.02276175559704\n",
      "min_loss= 12.625908963969925\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 11.112094403440471\n",
      "min_loss= 11.02276175559704\n",
      "loss= 9.8020097705878\n",
      "min_loss= 11.112094403440471\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 9.944124071839582\n",
      "min_loss= 9.8020097705878\n",
      "loss= 8.846828402162792\n",
      "min_loss= 9.944124071839582\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 9.042198900172933\n",
      "min_loss= 8.846828402162792\n",
      "loss= 8.098227605505238\n",
      "min_loss= 9.042198900172933\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 8.313854727420624\n",
      "min_loss= 8.098227605505238\n",
      "loss= 7.491151056803585\n",
      "min_loss= 8.313854727420624\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 7.708240652861509\n",
      "min_loss= 7.491151056803585\n",
      "loss= 6.945380670145466\n",
      "min_loss= 7.708240652861509\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 7.237102770757225\n",
      "min_loss= 6.945380670145466\n",
      "loss= 6.525701641422223\n",
      "min_loss= 7.237102770757225\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 6.788769096799248\n",
      "min_loss= 6.525701641422223\n",
      "loss= 6.126262991081242\n",
      "min_loss= 6.788769096799248\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 6.425063128384889\n",
      "min_loss= 6.126262991081242\n",
      "loss= 5.800082702908547\n",
      "min_loss= 6.425063128384889\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 6.128558708184363\n",
      "min_loss= 5.800082702908547\n",
      "loss= 5.5123744540335515\n",
      "min_loss= 6.128558708184363\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 5.848927070918424\n",
      "min_loss= 5.5123744540335515\n",
      "loss= 5.267447650263059\n",
      "min_loss= 5.848927070918424\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 5.6312398439811915\n",
      "min_loss= 5.267447650263059\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enum1,acc_res1,max_acc1 = use_XGB_LGBM_framework(X_train,y_train,X_test,y_test)\n",
    "vizualize(enum1,acc_res1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "global single_results\n",
    "single_results = pd.DataFrame(columns=['r2'])\n",
    "\n",
    "global complex_results\n",
    "complex_results = pd.DataFrame(columns=['r2'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def train_model(concrete_model, x_train, y_train_f, x_test, y_test_f):\n",
    "    concrete_model.fit(x_train, y_train_f)\n",
    "    pred_train = concrete_model.predict(x_train)\n",
    "    pred_test = concrete_model.predict(x_test)\n",
    "    global single_results\n",
    "    single_results = single_results.append(\n",
    "        pd.DataFrame({'r2': [Accuracy_metric(y_test_f, pred_test)]}, index=[str(type(concrete_model).__name__)]))\n",
    "    return pred_train, pred_test\n",
    "\n",
    "def train_model_add_preds(concrete_model, x_train, y_train_f, x_test, y_test_f):\n",
    "    pred_train, pred_test = train_model(concrete_model, x_train, y_train_f, x_test, y_test_f)\n",
    "    x_train.insert(0, 'pre_result', pred_train)\n",
    "    x_test.insert(0, 'pre_result', pred_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "linear = LinearRegression()\n",
    "rf = RandomForestRegressor()\n",
    "xgb_1 = xgb.XGBRegressor(**xgb_params)\n",
    "lgbm_1 = lgb.LGBMRegressor(**lgbm_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(24488,)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_single = df_for_1_model.drop(columns=['price'], axis=1)\n",
    "y_train_single = df_for_1_model['price']\n",
    "X_train_single, X_test_single, y_train_single, y_test_single = split(X_train_single, y_train_single, train_size=0.8, random_state=18)\n",
    "\n",
    "\n",
    "y_test_single.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Study\\8_term\\Comp_vision\\L1\\venv\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "C:\\Study\\8_term\\Comp_vision\\L1\\venv\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 727\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n"
     ]
    }
   ],
   "source": [
    "models = [linear,rf,xgb_1,lgbm_1]\n",
    "for m in models:\n",
    "    train_model(m, X_train_single, y_train_single, X_test_single, y_test_single)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "single_results = single_results.append(pd.DataFrame({'r2': [r2_score(y_train, y_pred_train)]}, index=['ResNet']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "                             r2\nLinearRegression       0.199300\nRandomForestRegressor  0.587182\nXGBRegressor           0.411218\nLGBMRegressor          0.337794\nResNet                 0.592491",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LinearRegression</th>\n      <td>0.199300</td>\n    </tr>\n    <tr>\n      <th>RandomForestRegressor</th>\n      <td>0.587182</td>\n    </tr>\n    <tr>\n      <th>XGBRegressor</th>\n      <td>0.411218</td>\n    </tr>\n    <tr>\n      <th>LGBMRegressor</th>\n      <td>0.337794</td>\n    </tr>\n    <tr>\n      <th>ResNet</th>\n      <td>0.592491</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "['lgbm_1.joblib']"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(linear, \"linear.joblib\")\n",
    "joblib.dump(rf, \"rf.joblib\")\n",
    "joblib.dump(xgb_1, \"xgb_1.joblib\")\n",
    "joblib.dump(lgbm_1, \"lgbm_1.joblib\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "global complex_results\n",
    "complex_results = pd.DataFrame(columns=['r2'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Study\\8_term\\Comp_vision\\L1\\venv\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 1000000000000\n",
      "min_loss= inf\n",
      "loss= 18.99442289673498\n",
      "min_loss= 1000000000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 18.00801422554409\n",
      "min_loss= 18.99442289673498\n",
      "loss= 14.941469219289633\n",
      "min_loss= 18.00801422554409\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 14.686563159872614\n",
      "min_loss= 14.941469219289633\n",
      "loss= 12.573760913921381\n",
      "min_loss= 14.686563159872614\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 12.474816122590843\n",
      "min_loss= 12.573760913921381\n",
      "loss= 10.887413228633774\n",
      "min_loss= 12.474816122590843\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 10.923844672134685\n",
      "min_loss= 10.887413228633774\n",
      "loss= 9.616130524414904\n",
      "min_loss= 10.923844672134685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 9.727225564497822\n",
      "min_loss= 9.616130524414904\n",
      "loss= 8.649389962729561\n",
      "min_loss= 9.727225564497822\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 8.80187092352719\n",
      "min_loss= 8.649389962729561\n",
      "loss= 7.863538444456373\n",
      "min_loss= 8.80187092352719\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 8.024636571660524\n",
      "min_loss= 7.863538444456373\n",
      "loss= 7.178535547243857\n",
      "min_loss= 8.024636571660524\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 7.323628733576847\n",
      "min_loss= 7.178535547243857\n",
      "loss= 6.548536602401253\n",
      "min_loss= 7.323628733576847\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 6.723933899941592\n",
      "min_loss= 6.548536602401253\n",
      "loss= 6.023482787311815\n",
      "min_loss= 6.723933899941592\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 6.199792220849714\n",
      "min_loss= 6.023482787311815\n",
      "loss= 5.5386661785216935\n",
      "min_loss= 6.199792220849714\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 5.777173012561491\n",
      "min_loss= 5.5386661785216935\n",
      "loss= 5.181826709353075\n",
      "min_loss= 5.777173012561491\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 5.443465742661802\n",
      "min_loss= 5.181826709353075\n",
      "loss= 4.833826034231962\n",
      "min_loss= 5.443465742661802\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 5.136815381012546\n",
      "min_loss= 4.833826034231962\n",
      "loss= 4.556633714934407\n",
      "min_loss= 5.136815381012546\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 4.85257409228527\n",
      "min_loss= 4.556633714934407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Study\\8_term\\Comp_vision\\L1\\venv\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 1000000000000\n",
      "min_loss= inf\n",
      "loss= 4.022253388755889\n",
      "min_loss= 1000000000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 4.223661504897294\n",
      "min_loss= 4.022253388755889\n",
      "loss= 3.5548147081353907\n",
      "min_loss= 4.223661504897294\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 3.865243669731843\n",
      "min_loss= 3.5548147081353907\n",
      "loss= 3.2978637569930775\n",
      "min_loss= 3.865243669731843\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 3.6385475812514843\n",
      "min_loss= 3.2978637569930775\n",
      "loss= 3.0974468265806823\n",
      "min_loss= 3.6385475812514843\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 3.4609910504589543\n",
      "min_loss= 3.0974468265806823\n",
      "loss= 2.961970780858456\n",
      "min_loss= 3.4609910504589543\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 3.355929015980484\n",
      "min_loss= 2.961970780858456\n",
      "loss= 2.856890372906888\n",
      "min_loss= 3.355929015980484\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 3.2567639508665644\n",
      "min_loss= 2.856890372906888\n",
      "loss= 2.739195370965562\n",
      "min_loss= 3.2567639508665644\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 3.17954149877082\n",
      "min_loss= 2.739195370965562\n",
      "loss= 2.6743796524599377\n",
      "min_loss= 3.17954149877082\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 3.1128182333070376\n",
      "min_loss= 2.6743796524599377\n",
      "loss= 2.6223552084522583\n",
      "min_loss= 3.1128182333070376\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 3.055155431765634\n",
      "min_loss= 2.6223552084522583\n",
      "loss= 2.5510858844649884\n",
      "min_loss= 3.055155431765634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 2.9664327669726798\n",
      "min_loss= 2.5510858844649884\n",
      "loss= 2.504012141859428\n",
      "min_loss= 2.9664327669726798\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 2.9549951752077037\n",
      "min_loss= 2.504012141859428\n",
      "loss= 2.4571114121448083\n",
      "min_loss= 2.9549951752077037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 2.9155836709292595\n",
      "min_loss= 2.4571114121448083\n",
      "loss= 2.431841603105239\n",
      "min_loss= 2.9155836709292595\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 2.8901674674599844\n",
      "min_loss= 2.431841603105239\n",
      "loss= 2.4012939156611868\n",
      "min_loss= 2.8901674674599844\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 2.8907489950988627\n",
      "min_loss= 2.4012939156611868\n",
      "loss= 1000000000000\n",
      "min_loss= inf\n",
      "loss= 15.283363014566598\n",
      "min_loss= 1000000000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 14.910219026505969\n",
      "min_loss= 15.283363014566598\n",
      "loss= 12.65408604765562\n",
      "min_loss= 14.910219026505969\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 12.531190965031394\n",
      "min_loss= 12.65408604765562\n",
      "loss= 10.88767144656041\n",
      "min_loss= 12.531190965031394\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 10.891061864227316\n",
      "min_loss= 10.88767144656041\n",
      "loss= 9.589349665296629\n",
      "min_loss= 10.891061864227316\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 9.673439833900257\n",
      "min_loss= 9.589349665296629\n",
      "loss= 8.576231631947593\n",
      "min_loss= 9.673439833900257\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 8.698077018627714\n",
      "min_loss= 8.576231631947593\n",
      "loss= 7.700278119535213\n",
      "min_loss= 8.698077018627714\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 7.8253429236951995\n",
      "min_loss= 7.700278119535213\n",
      "loss= 6.9842727859580345\n",
      "min_loss= 7.8253429236951995\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 7.142639711018213\n",
      "min_loss= 6.9842727859580345\n",
      "loss= 6.3845055581728305\n",
      "min_loss= 7.142639711018213\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 6.515721634702951\n",
      "min_loss= 6.3845055581728305\n",
      "loss= 5.835970509286194\n",
      "min_loss= 6.515721634702951\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 6.026228202768253\n",
      "min_loss= 5.835970509286194\n",
      "loss= 5.41120199646439\n",
      "min_loss= 6.026228202768253\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 5.646656891631388\n",
      "min_loss= 5.41120199646439\n",
      "loss= 5.030145182887302\n",
      "min_loss= 5.646656891631388\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 5.301890273794172\n",
      "min_loss= 5.030145182887302\n",
      "loss= 4.694697676667035\n",
      "min_loss= 5.301890273794172\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 4.991127668334787\n",
      "min_loss= 4.694697676667035\n",
      "loss= 4.406541217428691\n",
      "min_loss= 4.991127668334787\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 4.741572823408699\n",
      "min_loss= 4.406541217428691\n",
      "loss= 4.185186249304289\n",
      "min_loss= 4.741572823408699\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 4.511729195074169\n",
      "min_loss= 4.185186249304289\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 727\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 88\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 1000000000000\n",
      "min_loss= inf\n",
      "loss= 18.74523390310071\n",
      "min_loss= 1000000000000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 17.8652187619488\n",
      "min_loss= 18.74523390310071\n",
      "loss= 14.8086211365171\n",
      "min_loss= 17.8652187619488\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 14.530318381462537\n",
      "min_loss= 14.8086211365171\n",
      "loss= 12.4438002805998\n",
      "min_loss= 14.530318381462537\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 12.351635706541368\n",
      "min_loss= 12.4438002805998\n",
      "loss= 10.730887737694328\n",
      "min_loss= 12.351635706541368\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 10.78444305224208\n",
      "min_loss= 10.730887737694328\n",
      "loss= 9.450485402586462\n",
      "min_loss= 10.78444305224208\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 9.555884255018714\n",
      "min_loss= 9.450485402586462\n",
      "loss= 8.451693320089387\n",
      "min_loss= 9.555884255018714\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 8.610040435041064\n",
      "min_loss= 8.451693320089387\n",
      "loss= 7.661231712805275\n",
      "min_loss= 8.610040435041064\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 7.81210507673399\n",
      "min_loss= 7.661231712805275\n",
      "loss= 6.964097125321461\n",
      "min_loss= 7.81210507673399\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 7.139063831961606\n",
      "min_loss= 6.964097125321461\n",
      "loss= 6.359055567800692\n",
      "min_loss= 7.139063831961606\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 6.547628618462102\n",
      "min_loss= 6.359055567800692\n",
      "loss= 5.863187821574352\n",
      "min_loss= 6.547628618462102\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 6.089944713971987\n",
      "min_loss= 5.863187821574352\n",
      "loss= 5.435828241859113\n",
      "min_loss= 6.089944713971987\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 5.682540667488901\n",
      "min_loss= 5.435828241859113\n",
      "loss= 5.074061181585901\n",
      "min_loss= 5.682540667488901\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 5.332381758132397\n",
      "min_loss= 5.074061181585901\n",
      "loss= 4.728899330463722\n",
      "min_loss= 5.332381758132397\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 5.039468515585748\n",
      "min_loss= 4.728899330463722\n",
      "loss= 4.46676158792208\n",
      "min_loss= 5.039468515585748\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 982\n",
      "[LightGBM] [Info] Number of data points in the train set: 97948, number of used features: 89\n",
      "[LightGBM] [Info] Start training from score 18007.696931\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "loss= 4.796928817696038\n",
      "min_loss= 4.46676158792208\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "X_train_single = df_for_1_model.drop(columns=['price'], axis=1)\n",
    "y_train_single = df_for_1_model['price']\n",
    "X_train_single, X_test_single, y_train_single, y_test_single = split(X_train_single, y_train_single, train_size=0.8, random_state=18)\n",
    "for m in models:\n",
    "    train_model_add_preds(m,X_train_single, y_train_single, X_test_single, y_test_single)\n",
    "\n",
    "    enum1,acc_res1,max_acc1 = use_XGB_LGBM_framework(X_train_single,y_train_single,X_test_single,y_test_single)\n",
    "    accuracies.append(acc_res1)\n",
    "    complex_results = complex_results.append(\n",
    "        pd.DataFrame({'r2': [max_acc1]}, index=[str(type(m).__name__)]))\n",
    "    X_train_single = df_for_1_model.drop(columns=['price'], axis=1)\n",
    "    y_train_single = df_for_1_model['price']\n",
    "    X_train_single, X_test_single, y_train_single, y_test_single = split(X_train_single, y_train_single, train_size=0.8, random_state=18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "                             r2\nLinearRegression       0.199300\nRandomForestRegressor  0.587182\nXGBRegressor           0.411218\nLGBMRegressor          0.337794\nResNet                 0.592491",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LinearRegression</th>\n      <td>0.199300</td>\n    </tr>\n    <tr>\n      <th>RandomForestRegressor</th>\n      <td>0.587182</td>\n    </tr>\n    <tr>\n      <th>XGBRegressor</th>\n      <td>0.411218</td>\n    </tr>\n    <tr>\n      <th>LGBMRegressor</th>\n      <td>0.337794</td>\n    </tr>\n    <tr>\n      <th>ResNet</th>\n      <td>0.592491</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "complex_results = complex_results.append(\n",
    "        pd.DataFrame({'r2': [max_acc1]}, index=['ResNet']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "                             r2\nLinearRegression       0.791126\nRandomForestRegressor  0.891778\nXGBRegressor           0.806782\nLGBMRegressor          0.798678\nResNet                 0.752731",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LinearRegression</th>\n      <td>0.791126</td>\n    </tr>\n    <tr>\n      <th>RandomForestRegressor</th>\n      <td>0.891778</td>\n    </tr>\n    <tr>\n      <th>XGBRegressor</th>\n      <td>0.806782</td>\n    </tr>\n    <tr>\n      <th>LGBMRegressor</th>\n      <td>0.798678</td>\n    </tr>\n    <tr>\n      <th>ResNet</th>\n      <td>0.752731</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "e = range(1,30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for m in accuracies:\n",
    "    plt.plot(e,m)\n",
    "\n",
    "plt.legend(['linear', 'rf','xgb','lgbm'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}